{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install openai python-dotenv langchain faiss-cpu pandas\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "import faiss\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class RAGSystem:\n",
    "    def __init__(self, embedding_model=\"text-embedding-3-small\", completion_model=\"gpt-4o-mini\"):\n",
    "        \"\"\"Initialize the RAG system with OpenAI models.\"\"\"\n",
    "        self.client = OpenAI()\n",
    "        self.embedding_model = embedding_model\n",
    "        self.completion_model = completion_model\n",
    "        self.documents = []\n",
    "        self.index = None\n",
    "        self.document_store = {}\n",
    "        \n",
    "    def add_documents(self, documents: List[str], metadatas: List[Dict[str, Any]] = None):\n",
    "        \"\"\"Add documents to the RAG system and create embeddings.\"\"\"\n",
    "        if metadatas is None:\n",
    "            metadatas = [{} for _ in range(len(documents))]\n",
    "            \n",
    "        # Store original documents with their metadata\n",
    "        start_idx = len(self.documents)\n",
    "        for i, (doc, meta) in enumerate(zip(documents, metadatas)):\n",
    "            idx = start_idx + i\n",
    "            self.document_store[idx] = {\"content\": doc, \"metadata\": meta}\n",
    "            self.documents.append(doc)\n",
    "        \n",
    "        # Generate embeddings\n",
    "        embeddings = self._get_embeddings(documents)\n",
    "        \n",
    "        # Create or update the FAISS index\n",
    "        if self.index is None:\n",
    "            self._create_index(embeddings)\n",
    "        else:\n",
    "            self._update_index(embeddings)\n",
    "            \n",
    "        print(f\"Added {len(documents)} documents. Total documents: {len(self.documents)}\")\n",
    "    \n",
    "    def _get_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings for the given texts using OpenAI.\"\"\"\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            response = self.client.embeddings.create(\n",
    "                model=self.embedding_model,\n",
    "                input=text\n",
    "            )\n",
    "            embeddings.append(response.data[0].embedding)\n",
    "        return np.array(embeddings, dtype=np.float32)\n",
    "    \n",
    "    def _create_index(self, embeddings: np.ndarray):\n",
    "        \"\"\"Create a new FAISS index with the embeddings.\"\"\"\n",
    "        vector_dimension = len(embeddings[0])\n",
    "        self.index = faiss.IndexFlatL2(vector_dimension)\n",
    "        self.index.add(embeddings)\n",
    "    \n",
    "    def _update_index(self, new_embeddings: np.ndarray):\n",
    "        \"\"\"Update the existing FAISS index with new embeddings.\"\"\"\n",
    "        self.index.add(new_embeddings)\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Retrieve relevant documents based on the query.\"\"\"\n",
    "        # Generate query embedding\n",
    "        query_embedding = self._get_embeddings([query])[0].reshape(1, -1)\n",
    "        \n",
    "        # Search for similar documents\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # Get the retrieved documents\n",
    "        results = []\n",
    "        for i, idx in enumerate(indices[0]):\n",
    "            if idx < len(self.documents) and idx >= 0:\n",
    "                doc_info = self.document_store[idx]\n",
    "                results.append({\n",
    "                    \"content\": doc_info[\"content\"],\n",
    "                    \"metadata\": doc_info[\"metadata\"],\n",
    "                    \"score\": float(distances[0][i])\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate(self, query: str, top_k: int = 3, temperature: float = 0.7) -> str:\n",
    "        \"\"\"Generate a response using RAG approach.\"\"\"\n",
    "        # Retrieve relevant documents\n",
    "        retrieved_docs = self.retrieve(query, top_k=top_k)\n",
    "        \n",
    "        # Construct the context from retrieved documents\n",
    "        context = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc['content']}\" for i, doc in enumerate(retrieved_docs)])\n",
    "        \n",
    "        # Create the augmented prompt\n",
    "        system_prompt = f\"\"\"You are a helpful assistant. Use the following retrieved documents to answer the user's question. \n",
    "If you cannot answer the question based on the documents, say so.\n",
    "\n",
    "Retrieved documents:\n",
    "{context}\"\"\"\n",
    "        \n",
    "        # Generate completion with the augmented prompt\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.completion_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def save(self, path: str = \"rag_system\"):\n",
    "        \"\"\"Save the RAG system to disk.\"\"\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        # Save the documents and document store\n",
    "        with open(os.path.join(path, \"document_store.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.document_store, f)\n",
    "            \n",
    "        with open(os.path.join(path, \"documents.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.documents, f)\n",
    "            \n",
    "        # Save the FAISS index\n",
    "        if self.index is not None:\n",
    "            faiss.write_index(self.index, os.path.join(path, \"index.faiss\"))\n",
    "            \n",
    "        print(f\"RAG system saved to {path}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path: str = \"rag_system\", embedding_model=\"text-embedding-3-small\", completion_model=\"gpt-4o-mini\"):\n",
    "        \"\"\"Load a saved RAG system from disk.\"\"\"\n",
    "        rag = cls(embedding_model=embedding_model, completion_model=completion_model)\n",
    "        \n",
    "        # Load the documents and document store\n",
    "        with open(os.path.join(path, \"document_store.pkl\"), \"rb\") as f:\n",
    "            rag.document_store = pickle.load(f)\n",
    "            \n",
    "        with open(os.path.join(path, \"documents.pkl\"), \"rb\") as f:\n",
    "            rag.documents = pickle.load(f)\n",
    "            \n",
    "        # Load the FAISS index if it exists\n",
    "        index_path = os.path.join(path, \"index.faiss\")\n",
    "        if os.path.exists(index_path):\n",
    "            rag.index = faiss.read_index(index_path)\n",
    "            \n",
    "        print(f\"RAG system loaded from {path}\")\n",
    "        print(f\"Total documents: {len(rag.documents)}\")\n",
    "        \n",
    "        return rag\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a new RAG system\n",
    "    rag = RAGSystem()\n",
    "    \n",
    "    # Example documents about travel destinations\n",
    "    documents = [\n",
    "        \"Hawaii is known for its stunning beaches, volcanic landscapes, and rich Polynesian culture. The islands offer activities like surfing, snorkeling, and hiking. Best time to visit is between March and September.\",\n",
    "        \"Paris, France is famous for the Eiffel Tower, Louvre Museum, and exquisite cuisine. The city is ideal for art lovers, romantics, and food enthusiasts. Best time to visit is April to June or October to November.\",\n",
    "        \"Tokyo, Japan blends traditional culture with futuristic technology. Visitors can explore ancient temples, enjoy cherry blossoms in spring, and experience world-class shopping and dining. Best time to visit is March-April or October-November.\",\n",
    "        \"Santorini, Greece features iconic white buildings with blue domes overlooking the Aegean Sea. The island is perfect for couples seeking romantic sunsets, beaches, and Mediterranean cuisine. Best time to visit is April to October.\",\n",
    "        \"Bali, Indonesia offers lush rice terraces, spiritual temples, and vibrant beach resorts. Popular activities include surfing, yoga retreats, and traditional dance performances. Best time to visit is April to October.\"\n",
    "    ]\n",
    "    \n",
    "    # Add documents to the RAG system\n",
    "    rag.add_documents(documents)\n",
    "    \n",
    "    # Example query\n",
    "    query = \"What's a good destination for a beach vacation?\"\n",
    "    \n",
    "    # Generate a response using RAG\n",
    "    response = rag.generate(query)\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
